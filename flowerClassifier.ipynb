{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flowerClassifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "4eaS9l3Zdzyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import tarfile\n",
        "import os\n",
        "from six.moves import urllib\n",
        "\n",
        "FLOWERS_URL = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "FLOWERS_PATH = os.path.join(\"datasets\", \"flowers\")\n",
        "\n",
        "def download_progress(count, block_size, total_size):\n",
        "    percent = count * block_size * 100 // total_size\n",
        "    sys.stdout.write(\"\\rDownloading: {}%\".format(percent))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def fetch_flowers(url=FLOWERS_URL, path=FLOWERS_PATH):\n",
        "    if os.path.exists(FLOWERS_PATH):\n",
        "        return\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    tgz_path = os.path.join(path, \"flower_photos.tgz\")\n",
        "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
        "    flowers_tgz = tarfile.open(tgz_path)\n",
        "    flowers_tgz.extractall(path=path)\n",
        "    flowers_tgz.close()\n",
        "    #os.remove(tgz_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "duA0dFmgeufS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#urllib.request.urlretrieve(FLOWERS_URL, os.path.join(FLOWERS_PATH,'flower_photos.tgz'), reporthook=download_progress)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKkR-h_wezQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c16537d8-3486-4f13-b9a1-dfb331397de8"
      },
      "cell_type": "code",
      "source": [
        "flowers_root_path = os.path.join(FLOWERS_PATH, \"flower_photos\")\n",
        "fetch_flowers()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: 67%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FtFTZQ-XfEtW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in os.listdir(flowers_root_path):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iB94hrFcfKxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flower_classes = sorted([dirname for dirname in os.listdir(flowers_root_path)\n",
        "                  if os.path.isdir(os.path.join(flowers_root_path, dirname))])\n",
        "flower_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "734V2gB8fmlI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls datasets/flowers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZFWW2TsgHHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4sQQKk2gJ33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDVXVRnbgwfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "image_paths = defaultdict(list)\n",
        "\n",
        "for flower_class in flower_classes:\n",
        "    image_dir = os.path.join(flowers_root_path, flower_class)\n",
        "    for filepath in os.listdir(image_dir):\n",
        "        if filepath.endswith(\".jpg\"):\n",
        "            image_paths[flower_class].append(os.path.join(image_dir, filepath))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2DV4r95sS1-J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for paths in image_paths.values():\n",
        "  paths.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHSYqHWLS6Tg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "channels = 3\n",
        "ex_per_class = 2\n",
        "\n",
        "for c in flower_classes:\n",
        "  print('class:', c)\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  for i, expath in enumerate(image_paths[c][:ex_per_class]):\n",
        "    eximg = mpimg.imread(expath)[:, :, :channels]\n",
        "    plt.subplot(100 + ex_per_class * 10 + i + 1)\n",
        "    plt.title('{}x{}'.format(eximg.shape[1], eximg.shape[0]))\n",
        "    plt.imshow(eximg)\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# for c in flower_classes:\n",
        "#     print('class:', c)\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     for i, expath in enumerate(image_paths[c][:ex_per_class]):\n",
        "#         eximg = mpimg.imread(expath)[:, :, :channels]\n",
        "#         plt.subplot(100 + ex_per_class * 10 + i + 1)\n",
        "#         plt.title('{}x{}'.format(eximg.shape[1], eximg.shape[0]))\n",
        "#         plt.imshow(eximg)\n",
        "#         plt.axis('off')\n",
        "#     plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P3RkagNgT7kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "def augment(im, width = 299, height = 299, zoom = 0.2):\n",
        "  \n",
        "  h = im.shape[0]\n",
        "  w = im.shape[1]\n",
        "  image_ratio = w / h\n",
        "  t_image_ratio = width / height\n",
        "  crop_vert = image_ratio < t_image_ratio\n",
        "  crop_w = w if crop_vert else int(h * t_image_ratio)\n",
        "  crop_l = int(w * t_image_ratio) if crop_vert else h\n",
        " \n",
        "  resize  = np.random.rand() * zoom + 1.0\n",
        "  crop_w = int(crop_w * resize)\n",
        "  crop_l = int(crop_l * resize)\n",
        "  \n",
        "  x0 = np.random.randint(0, w - crop_w)\n",
        "  y0 = np.random.randint(0, h - crop_l)\n",
        "  x1 = x0 + crop_w\n",
        "  y1 = y0 + crop_l\n",
        "  \n",
        "  im = im[y0:y1, x0:x1]\n",
        "  if np.random.rand() < .5:\n",
        "    im = np.fliplr(im)\n",
        "    \n",
        "  im = resize(im, (width, height))\n",
        "  return im.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcUDItsqXHFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tfaugment(im, width = 299, height = 299, zoom = 0.2):\n",
        "  \n",
        "  sh = tf.cast(tf.shape(im), tf.float32)\n",
        "  h = sh[0]\n",
        "  w = sh[1]\n",
        "  image_ratio = w / h\n",
        "  t_image_ratio = width / height\n",
        "  crop_vert = image_ratio < t_image_ratio\n",
        "  crop_w = tf.cond(crop_vert, lambda: w, lambda: h * t_image_ratio)\n",
        "  crop_l = tf.cond(crop_vert, lambda: w / image_ratio, lambda: h)\n",
        " \n",
        "  resize  = tf.random_uniform(shape = [], minval = 1.0, maxval = 1.0 + zoom)\n",
        "  crop_w = tf.cast(crop_w / resize, tf.int32)\n",
        "  crop_l = tf.cast(crop_l / resize, tf.int32)\n",
        "  box = tf.stack([crop_w, crop_l, 3])\n",
        "  \n",
        "  im = tf.random_crop(im, box)\n",
        "  \n",
        "  im = tf.image.random_flip_left_right(im)\n",
        "  \n",
        "  im_batch = tf.expand_dims(im, 0)\n",
        "  \n",
        "  im_batch = tf.image.resize_bilinear(im_batch, [height, width])\n",
        "  \n",
        "  im = im_batch[0] / 255\n",
        "  \n",
        "  return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6UV--8C4XHM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib.slim.nets import inception\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "width = height = 299\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape = [None, width, height, channels], name = 'x')\n",
        "train = tf.placeholder_with_default(False, shape = [])\n",
        "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
        "  logits, endpoints = inception.inception_v3(x, num_classes = 1001, is_training = train)\n",
        "\n",
        "ins_saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZ1eP5NtcZTE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logits.op.inputs[0].op.inputs[0].op.inputs[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jvg2bd2yc7hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "endpoints['PreLogits']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppYOoGN7dBeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prelogits = tf.squeeze(endpoints['PreLogits'], axis = [1, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBrnVGFmdfoO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nout = len(flower_classes)\n",
        "with tf.name_scope('new_out'):\n",
        "  f_logits = tf.layers.dense(prelogits, nout, name = 'f_logits')\n",
        "  y_prob = tf.nn.softmax(f_logits, name = 'y_prob')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RMQllngVdzKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y = tf.placeholder(tf.int32, shape = [None])\n",
        "with tf.name_scope('train'):\n",
        "  xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = f_logits, labels = y)\n",
        "  loss = tf.reduce_mean(xentropy)\n",
        "  optim = tf.train.AdamOptimizer()\n",
        "  f_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'f_logits')\n",
        "  training_op = optim.minimize(loss, var_list = f_vars)\n",
        "  \n",
        "with tf.name_scope('eval'):\n",
        "  correct = tf.nn.in_top_k(f_logits, y, 1)\n",
        "  acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "  \n",
        "with tf.name_scope('init'):\n",
        "  init = tf.global_variables_initializer()\n",
        "  saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVJxuB18_c5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_ids = {flower_class: i for i, flower_class in enumerate(flower_classes)}\n",
        "f_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RhL5dctR_zrq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flower_paths_class = []\n",
        "for i, j in image_paths.items():\n",
        "  for path in j:\n",
        "    flower_paths_class.append((path, f_ids[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUg2BGX6ATiM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "tst_ratio = 0.2\n",
        "train_size = int(len(flower_paths_class) * (1 - tst_ratio))\n",
        "\n",
        "np.random.shuffle(flower_paths_class)\n",
        "flower_train = flower_paths_class[:train_size]\n",
        "flower_tst = flower_paths_class[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liSYco_pApTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import sample\n",
        "\n",
        "def prepare_batch(flower_paths_and_classes, batch_size):\n",
        "    batch_paths_and_classes = sample(flower_paths_and_classes, batch_size)\n",
        "    images = [mpimg.imread(path)[:, :, :channels] for path, labels in batch_paths_and_classes]\n",
        "    prepared_images = [tfaugment(image) for image in images]\n",
        "    X_batch = 2 * np.stack(prepared_images) - 1 \n",
        "    y_batch = np.array([labels for path, labels in batch_paths_and_classes], dtype=np.int32)\n",
        "    return X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBHYU9CNFXZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_bat, y_bat = prepare_batch(flower_train, batch_size = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4oQa46rFiWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_bat.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9RoqdQyNFlGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_bat.dtype"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmjCqhCuFm7l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_bat.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0SYcYR-FquE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_tst, y_tst = prepare_batch(flower_tst, batch_size = len(flower_tst))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TUSx4Sg3Gm3M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TF_MODELS_URL = \"http://download.tensorflow.org/models\"\n",
        "INCEPTION_V3_URL = TF_MODELS_URL + \"/inception_v3_2016_08_28.tar.gz\"\n",
        "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
        "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
        "\n",
        "def download_progress(count, block_size, total_size):\n",
        "    percent = count * block_size * 100 // total_size\n",
        "    sys.stdout.write(\"\\rDownloading: {}%\".format(percent))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=INCEPTION_PATH):\n",
        "    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n",
        "        return\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    tgz_path = os.path.join(path, \"inception_v3.tgz\")\n",
        "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
        "    inception_tgz = tarfile.open(tgz_path)\n",
        "    inception_tgz.extractall(path=path)\n",
        "    inception_tgz.close()\n",
        "    os.remove(tgz_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ndFEg51ZGnW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch = 40\n",
        "iters = len(flower_train) // batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  ins_saver.restore(sess, INCEPTION_V3_CHECKPOINT_PATH)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    print('epoch: ', epoch, end = '')\n",
        "    for iter in range(iters):\n",
        "      print('.', end = '')\n",
        "      x_bat, y_bat = prepare_batch(flower_train, batch)\n",
        "#       print(x_bat)\n",
        "#       print(y_bat)\n",
        "      sess.run(training_op, feed_dict = {x: x_bat, y: y_bat})\n",
        "      \n",
        "    acc = accuracy.eval(feed_dict = {x: x_bat, y: y_bat})\n",
        "    print('last batch acc: ', acc)\n",
        "    \n",
        "    save_path = saver.save(sess, './my_flowers_model')\n",
        "fetch_pretrained_inception_v3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBYLJyhzZfkm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAovLo2osLQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_-ZvcJxsOri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tst_batches = 10\n",
        "x_tst_batches = np.array_split(x_tst, tst_batches)\n",
        "y_tst_batches = np.array_split(y_tst, tst_batches)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, './my_flower_model')\n",
        "  \n",
        "  print('final acc:')\n",
        "  acc_tst = np.mean([accuracy.eval(feed_dict = {x: x_tst_bat, y: y_tst_bat}) for x_tst_bat, y_tst_bat in zip(x_tst_batches, y_tst_batches)])\n",
        "  print('final!: ', acc_tst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_f4Kj3VT9P7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}